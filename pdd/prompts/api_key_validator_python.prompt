<pdd-reason>Validates API keys using llm_invoke with minimal test prompts for all LLM providers.</pdd-reason>

<pdd-interface>
{
  "type": "module",
  "module": {
    "functions": [
      {"name": "validate_key", "signature": "(key_name: str, key_value: str) -> ValidationResult", "returns": "ValidationResult"}
    ]
  }
}
</pdd-interface>

% You are an expert Python engineer. Your goal is to write the pdd/setup/api_key_validator.py module.

% Role & Scope
This module validates API keys by testing them with llm_invoke instead of hardcoded HTTP requests. It selects an appropriate test model for each provider, makes a minimal completion request, and returns validation results including error details.

% Requirements
1. Function: `validate_key(key_name: str, key_value: str) -> ValidationResult` - Test if API key works
2. Use llm_invoke: Call pdd.llm_invoke.llm_invoke() with minimal test prompt instead of HTTP requests
3. Model selection: Map API key name to appropriate test model (e.g., ANTHROPIC_API_KEY -> claude-haiku-4-5)
4. Test prompt: Use simple prompt like "Say 'OK'" to minimize cost and latency
5. Error handling: Catch authentication errors, network errors, and invalid model errors separately
6. ValidationResult: Return dataclass with fields: is_valid (bool), provider (str), model_tested (str), error_message (Optional[str])
7. Provider mapping: Derive provider from key name (ANTHROPIC_API_KEY -> Anthropic, OPENAI_API_KEY -> OpenAI, etc.)
8. Timeout: Set reasonable timeout (10s) for validation requests to avoid hanging
9. Cost awareness: Always use cheapest/fastest model for validation (Haiku for Anthropic, cheapest GPT model available for OpenAI, Gemini Flash for Google)
10. Vertex AI handling: For VERTEX_CREDENTIALS, test with vertex_ai/ prefix models

% Dependencies
<llm_invoke_example>
  <include>context/llm_invoke_example.py</include>
</llm_invoke_example>

<llm_model_csv_schema>
The CSV at pdd/data/llm_model.csv has columns:
provider,model,input,output,coding_arena_elo,base_url,api_key,max_reasoning_tokens,structured_output,reasoning_type,location

Example rows:
- Anthropic,anthropic/claude-haiku-4-5-20251001,1.0,5.0,1270,,ANTHROPIC_API_KEY,128000,True,budget,
- OpenAI,gpt-4o-mini,0.15,0.6,1249,,OPENAI_API_KEY,0,True,none,
- Google,vertex_ai/gemini-3-flash-preview,0.5,3.0,1430,,VERTEX_CREDENTIALS,0,True,effort,global
</llm_model_csv_schema>

% Instructions
- Map key names to providers: ANTHROPIC_API_KEY -> Anthropic, OPENAI_API_KEY -> OpenAI, GEMINI_API_KEY -> Google, VERTEX_CREDENTIALS -> Google (Vertex), FIREWORKS_API_KEY -> Fireworks, GROQ_API_KEY -> Groq
- Select cheapest model for each provider from CSV for validation
- Set key as environment variable temporarily before calling llm_invoke (if not already set)
- Use try/except to catch litellm errors and categorize them (auth vs network vs config)
- Return ValidationResult dataclass with clear error messages for debugging
- Don't raise exceptions to caller, always return ValidationResult
- Log validation attempts and results for debugging

% Deliverables
- A Python module located at `pdd/setup/api_key_validator.py`.
- The module must export the following symbols:
  - `validate_key`: Tests if an API key is valid by making a minimal test request.
  - `ValidationResult`: A dataclass containing the result of the validation.
