<include>context/python_preamble.prompt</include>

% Goal
Write the pdd/agentic_common.py module.

% Role & Scope
Shared infrastructure for agentic CLI invocations (Claude Code, Gemini, Codex). Provides reusable utilities for agent discovery, environment sanitization, logging, and subprocess orchestration.

% CLI Documentation (headless mode, JSON output, permissions)
<claude_code_json_output>
<web>https://claudelog.com/faqs/what-is-output-format-in-claude-code/</web>
</claude_code_json_output>

<gemini_cli_headless>
<web>https://geminicli.com/docs/cli/headless/</web>
</gemini_cli_headless>

<gemini_cli_sandbox>
<web>https://geminicli.com/docs/cli/sandbox/</web>
</gemini_cli_sandbox>

<gemini_cli_pricing>
<web>https://geminicli.com/docs/quota-and-pricing/</web>
</gemini_cli_pricing>

<codex_cli_reference>
<web>https://developers.openai.com/codex/cli/reference</web>
</codex_cli_reference>

% Requirements
1. Export `AGENT_PROVIDER_PREFERENCE = ["anthropic", "google", "openai"]`
2. Provide logging utilities that accept `verbose: bool` and `quiet: bool` as function parameters (callers pass these from their context)
3. Check agent availability:
   - CLI command must exist (use `shutil.which`)
   - API key must be configured (via `_load_model_data()` from llm_invoke)
   - Exception: Anthropic is available if Claude CLI exists, even without API key (supports subscription auth)
4. Run agents in **headless mode** with JSON output for structured response parsing and real cost tracking. Each provider requires specific flags for auto-approval of file operations.
5. Write prompt to unique temp file (`.agentic_prompt_<random>.txt`), invoke CLI with agentic instruction, clean up
6. Sanitize environment for non-interactive subprocess execution (TERM=dumb, NO_COLOR=1, CI=1). For Anthropic, remove ANTHROPIC_API_KEY from env to force subscription auth.
7. Parse JSON output to extract actual cost:
   - Anthropic: `data["total_cost_usd"]` (USD directly); extract response from `data["result"]` or `data["response"]`
   - Google: Calculate from `data["stats"]["models"][model]["tokens"]` fields (prompt, candidates, cached)
   - OpenAI: Calculate from `data["usage"]` fields (input_tokens, output_tokens, cached_input_tokens)

% Function Signatures

`get_available_agents() -> List[str]`
- Returns list of available provider names (e.g., `["anthropic", "google"]`)
- Checks both CLI binary exists AND API key is configured

`run_agentic_task(instruction: str, cwd: Path, *, verbose: bool = False, quiet: bool = False, label: str = "", timeout: Optional[float] = None) -> Tuple[bool, str, float, str]`
- Tries providers in `AGENT_PROVIDER_PREFERENCE` order
- Returns (success, output, cost, provider_used)
- Optional `timeout` parameter overrides environment variable and default

% Environment Variables
- `PDD_AGENTIC_TIMEOUT`: Agent CLI timeout in seconds (default: 240)

% Per-Step Timeouts (Issue #256, #239)

Export workflow-specific timeout dictionaries:

`BUG_STEP_TIMEOUTS: Dict[int, float]` - For 9-step agentic bug workflow:
- Simple steps (1-3, 9): 240 seconds (setup, review, plan, final verify)
- Medium step (6): 340 seconds (verify fix plan)
- Complex steps (4, 5, 8): 600 seconds (reproduce, root cause, verify)
- Most complex step (7): 1000 seconds (generate fix)

`CHANGE_STEP_TIMEOUTS: Dict[int, float]` - For 9-step agentic change workflow:
- Simple steps (1, 2): 240 seconds (duplicate check, docs comparison)
- Medium steps (3, 4, 5, 6, 9): 340 seconds (research, clarify, docs changes, identify dev units, verify work)
- Complex step (7): 600 seconds (analyze prompt changes)
- Most complex step (8): 1000 seconds (implement changes)

`STEP_TIMEOUTS: Dict[int, float]` - Alias for `BUG_STEP_TIMEOUTS` (backward compatibility)

% False Positive Detection (Issue #261)
Export `MIN_VALID_OUTPUT_LENGTH: int = 50`

In `run_agentic_task()`, after a provider returns success, detect false positives:
- If `cost == 0.0` AND `len(message.strip()) < MIN_VALID_OUTPUT_LENGTH`:
  - This indicates no actual work was done (provider returned success without doing anything)
  - Log error: "Provider '{provider}' returned success but appears to be a false positive"
  - Treat as failure and try next provider (continue to fallback)
- Only return success if provider produces legitimate output (>= 50 chars) OR has non-zero cost

% Token Pricing (for providers that return tokens, not USD)
- Gemini: Refer to current pricing from CLI documentation above
- Codex: $1.50/1M input, $6/1M output (75% discount for cached tokens)

% CLI Invocation Pattern
Critical: Build agentic instruction pointing to temp file:
`"Read the file {prompt_file} for instructions. You have full file access to explore and modify files as needed."`

Provider commands (headless + JSON output + file write permissions):
- Anthropic: `["claude", "-p", <instruction>, "--dangerously-skip-permissions", "--output-format", "json"]`
- Google: `["gemini", "-p", <instruction>, "--yolo", "--output-format", "json"]`
- OpenAI: `["codex", "exec", "--full-auto", "--json", <instruction>]`

Notes:
- `--dangerously-skip-permissions` (Claude): allows file modifications without prompts
- `--yolo` (Gemini): auto-approves all operations without prompts
- `--full-auto` (Codex): exits read-only sandbox, allows file edits

% Dependencies
<module_dependencies>
  <pdd.llm_invoke><include>context/llm_invoke_example.py</include></pdd.llm_invoke>
</module_dependencies>

% Deliverables
- Code: `pdd/agentic_common.py`