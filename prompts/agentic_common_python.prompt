<include>context/python_preamble.prompt</include>

% Goal
Write the pdd/agentic_common.py module.

% Role & Scope
Shared infrastructure for agentic CLI invocations (Claude Code, Gemini, Codex). Provides reusable utilities for agent discovery, environment sanitization, logging, and subprocess orchestration.

% External Documentation
<claude_code_json_output>
<web>https://claudelog.com/faqs/what-is-output-format-in-claude-code/</web>
</claude_code_json_output>

<gemini_cli_headless>
<web>https://geminicli.com/docs/cli/headless/</web>
</gemini_cli_headless>

<gemini_cli_sandbox>
<web>https://geminicli.com/docs/cli/sandbox/</web>
</gemini_cli_sandbox>

<gemini_cli_pricing>
<web>https://geminicli.com/docs/quota-and-pricing/</web>
</gemini_cli_pricing>

<codex_cli_reference>
<web>https://developers.openai.com/codex/cli/reference</web>
</codex_cli_reference>

% Requirements
1. Export `AGENT_PROVIDER_PREFERENCE = ["anthropic", "google", "openai"]`
2. Provide logging utilities that accept `verbose: bool` and `quiet: bool` as function parameters (callers pass these from their context)
3. Check agent availability:
   - CLI command must exist (use `shutil.which`)
   - API key must be configured (via `_load_model_data()` from llm_invoke)
   - Exception: Anthropic is available if Claude CLI exists, even without API key (supports subscription auth)
4. Run agents in **headless mode** with JSON output for structured response parsing and real cost tracking. Each provider requires specific flags for auto-approval of file operations.
5. Write prompt to unique temp file (`.agentic_prompt_<random>.txt`), invoke CLI with agentic instruction, clean up
6. Sanitize environment for non-interactive subprocess execution (TERM=dumb, NO_COLOR=1, CI=1). For Anthropic, remove ANTHROPIC_API_KEY from env to force subscription auth.
7. Parse JSON output to extract actual cost:
   - Anthropic: `data["total_cost_usd"]` (USD directly); extract response from `data["result"]` or `data["response"]`
   - Google: Calculate from `data["stats"]["models"][model]["tokens"]` fields (prompt, candidates, cached)
   - OpenAI: Calculate from `data["usage"]` fields (input_tokens, output_tokens, cached_input_tokens)

% Function Signatures

`get_available_agents() -> List[str]`
- Returns list of available provider names (e.g., `["anthropic", "google"]`)
- Checks both CLI binary exists AND API key is configured

`run_agentic_task(instruction: str, cwd: Path, *, verbose: bool = False, quiet: bool = False, label: str = "", timeout: Optional[float] = None) -> Tuple[bool, str, float, str]`
- Tries providers in `AGENT_PROVIDER_PREFERENCE` order
- Returns (success, output, cost, provider_used)
- Optional `timeout` parameter overrides environment variable and default

% Default Timeout
Export `DEFAULT_TIMEOUT_SECONDS: float = 240.0` as fallback for orchestrators that don't specify step-specific timeouts.

Note: Per-step timeout dictionaries (BUG_STEP_TIMEOUTS, CHANGE_STEP_TIMEOUTS, E2E_FIX_STEP_TIMEOUTS) are defined in their respective orchestrator modules, not here. This keeps workflow-specific configuration with the workflow.

% False Positive Detection (Issue #261)
Export `MIN_VALID_OUTPUT_LENGTH: int = 50`

In `run_agentic_task()`, after a provider returns success, detect false positives:
- If `cost == 0.0` AND `len(message.strip()) < MIN_VALID_OUTPUT_LENGTH`:
  - This indicates no actual work was done (provider returned success without doing anything)
  - Log error: "Provider '{provider}' returned success but appears to be a false positive"
  - Treat as failure and try next provider (continue to fallback)
- Only return success if provider produces legitimate output (>= 50 chars) OR has non-zero cost

% Token Pricing (for providers that return tokens, not USD)
- Gemini: Refer to current pricing from CLI documentation above
- Codex: $1.50/1M input, $6/1M output (75% discount for cached tokens)

% CLI Invocation Pattern
Critical: Build agentic instruction pointing to temp file:
`"Read the file {prompt_file} for instructions. You have full file access to explore and modify files as needed."`

Provider commands (headless + JSON output + file write permissions):
- Anthropic: `["claude", "-p", <instruction>, "--dangerously-skip-permissions", "--output-format", "json"]`
- Google: `["gemini", "-p", <instruction>, "--yolo", "--output-format", "json"]`
- OpenAI: `["codex", "exec", "--full-auto", "--json", <instruction>]`

Notes:
- `--dangerously-skip-permissions` (Claude): allows file modifications without prompts
- `--yolo` (Gemini): auto-approves all operations without prompts
- `--full-auto` (Codex): exits read-only sandbox, allows file edits

% Error Handling
- Return `(False, "No agents available", 0.0, "")` if no providers have both CLI and API key configured
- Return `(False, "{provider} error: {message}", 0.0, provider)` on subprocess failure
- Try next provider in preference order on failure; return failure only if all providers fail
- Log false positive detection at error level before trying next provider

% GitHub State Persistence (Cross-Machine Resume)

Shared infrastructure for storing workflow state in GitHub issue comments using hidden HTML markers.
This enables workflows to resume from any machine with access to the repository.

Constants:
- `GITHUB_STATE_MARKER_START = "<!-- PDD_WORKFLOW_STATE:"`
- `GITHUB_STATE_MARKER_END = "-->"`

State Comment Format:
```html
<!-- PDD_WORKFLOW_STATE:change:issue-123
{
  "workflow": "change",
  "last_completed_step": 7,
  "step_outputs": {...},
  "total_cost": 0.45,
  "github_comment_id": 12345678
}
-->
```

Low-Level Functions:

`_build_state_marker(workflow_type: str, issue_number: int) -> str`
- Build unique marker prefix: `<!-- PDD_WORKFLOW_STATE:{workflow_type}:issue-{issue_number}`

`_serialize_state_comment(workflow_type: str, issue_number: int, state: Dict) -> str`
- Serialize state dict to hidden HTML comment format
- Include newline after marker, JSON body, then closing marker

`_parse_state_from_comment(body: str, workflow_type: str, issue_number: int) -> Optional[Dict]`
- Extract state JSON from comment body if marker matches
- Return None if marker not found or JSON parse fails

GitHub API Functions (use `gh` CLI):

`_find_state_comment(repo_owner: str, repo_name: str, issue_number: int, workflow_type: str, cwd: Path) -> Optional[Tuple[int, Dict]]`
- List comments via `gh api repos/{owner}/{repo}/issues/{number}/comments`
- Search for comment containing matching state marker
- Return (comment_id, state_dict) or None
- Handle missing `gh` CLI gracefully (return None, log warning)

`github_save_state(repo_owner: str, repo_name: str, issue_number: int, workflow_type: str, state: Dict, cwd: Path, comment_id: Optional[int] = None) -> Optional[int]`
- If comment_id provided: PATCH existing comment via `gh api -X PATCH repos/{owner}/{repo}/issues/comments/{comment_id} -f body=...`
- If no comment_id: POST new comment via `gh api -X POST repos/{owner}/{repo}/issues/{number}/comments -f body=...`
- Return comment_id on success, None on failure (log warning, never crash)

`github_load_state(repo_owner: str, repo_name: str, issue_number: int, workflow_type: str, cwd: Path) -> Tuple[Optional[Dict], Optional[int]]`
- Call `_find_state_comment` to load state from GitHub
- Return (state_dict, comment_id) or (None, None)

`github_clear_state(repo_owner: str, repo_name: str, issue_number: int, workflow_type: str, cwd: Path) -> bool`
- Find state comment, DELETE via `gh api -X DELETE repos/{owner}/{repo}/issues/comments/{comment_id}`
- Return True on success or if no comment found, False on error

High-Level Wrapper Functions (used by orchestrators):

`load_workflow_state(cwd: Path, issue_number: int, workflow_type: str, state_dir: Path, repo_owner: str, repo_name: str, use_github_state: bool = True) -> Tuple[Optional[Dict], Optional[int]]`
- If `use_github_state` and `_should_use_github_state()`: fetch from GitHub first
- If GitHub returns state: cache locally for fast subsequent reads, return (state, comment_id)
- If GitHub fails or disabled: try local file fallback
- Return (state, github_comment_id) or (None, None)
- Gracefully handle: missing gh CLI, API errors, permission errors

`save_workflow_state(cwd: Path, issue_number: int, workflow_type: str, state: Dict, state_dir: Path, repo_owner: str, repo_name: str, use_github_state: bool = True, github_comment_id: Optional[int] = None) -> Optional[int]`
- Always write to local file first (fast, reliable)
- If `use_github_state` and `_should_use_github_state()`: write to GitHub
- On GitHub failure: log warning, continue (local write succeeded)
- Return new/updated github_comment_id or None

`clear_workflow_state(cwd: Path, issue_number: int, workflow_type: str, state_dir: Path, repo_owner: str, repo_name: str, use_github_state: bool = True) -> None`
- Clear local state file
- If `use_github_state` and `_should_use_github_state()`: delete GitHub comment
- Log any errors but never raise (workflow completed successfully)

`_should_use_github_state(use_github_state: bool) -> bool`
- Return False if `use_github_state` parameter is False
- Return False if `PDD_NO_GITHUB_STATE=1` environment variable is set
- Return True otherwise

% Dependencies
<pdd.llm_invoke><include>context/llm_invoke_example.py</include></pdd.llm_invoke>

% Deliverables
- Code: `pdd/agentic_common.py`