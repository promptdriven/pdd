% You are an expert Python Software Engineer. Your goal is to write a python function, "fix_errors_from_unit_tests", that will fix unit test errors in a code file. All output to the console will be pretty print using the Python rich library.

% Here are the inputs and outputs of the function:
    Inputs:
        'unit_test' - A string containing the unit test code.
        'code' - A string containing the code under test.
        'error' - A string that contains the errors that need to be fixed.
        'strength' - A float between 0 and 1 that is the strength of the LLM model to use.       
    Outputs:
        'update_unit_test': Boolean indicating whether the unit test needs to be updated.
        'update_code': Boolean indicating whether the code under test needs to be updated.
        'fixed_unit_test' - a string that is the fixed unit test.
        'fixed_code' - a string that is the fixed code under test.

% Here is an example of a Langchain LCEL program: ```<./context/langchain_lcel_example.py>```

% Here is an example how to select the Langchain llm: ```<./context/llm_selector_example.py>``` 

% Here is an example how to postprocess the model output result: ```<./context/postprocess_example.py>``` 

% Here is an example how to use tiktoken: ```<./context/tiktoken_example.py>```

% This program will use Langchain to do the following:
    Step 1. Use $PDD_PATH environment variable to get the path to the project. Load the '$PDD_PATH/prompts/fix_errors_from_unit_tests_LLM.prompt' file. Also load the 'extract_unit_code_fix_LLM.prompt' from the same directory.
    Step 2. Then this will create a Langchain LCEL template from the fix_errors_from_unit_tests prompt.
    Step 3. This will use llm_selector and a temperature of 0 for the llm model.
    Step 4. This will run the code through the model using Langchain LCEL. 
        4a. Be sure to pass the following string parameters to the prompt during invoke:
            - 'unit_test'
            - 'code'
            - 'errors'
        4b. Pretty print a message letting the user know it is running and how many tokens (using tiktoken) are in the prompt and the cost. The cost from llm_selector is in dollars per million tokens.
    Step 5. This will pretty print the markdown formatting that is present in the result via the rich Markdown function. It will also pretty print the number of tokens in the result and the cost. Also, print out the total cost.
    Step 7. Then this will create a second Langchain LCEL template from the extract_unit_code_fix prompt.
    Step 8. This will use llm_selector with a strength setting of 0.5 instead of the strength function input above and a temperature of 0 for the llm model. However, instead of using String output, it will use the JSON output parser to get these keys: 'update_unit_test', 'update_code', 'fixed_unit_test' and 'fixed_code'.
    Step 9. This will run the code through the model using Langchain LCEL from Step 8. 
        9a. Be sure to pass the following string parameter to the prompt during invoke:
            - 'unit_test_fix': This is the result of the Langchain LCEL from Step 4.
        9b. Pretty print a message letting the user know it is running and how many tokens (using tiktoken) are in the prompt and the cost.
    Step 10. Print the total cost of both runs and return 'update_unit_test', 'update_code', 'fixed_unit_test' and 'fixed_code' from the JSON output parser.