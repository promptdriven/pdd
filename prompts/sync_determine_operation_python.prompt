# sync_determine_operation_python.prompt

You are an expert Python developer. Your task is to implement the core decision-making logic for the `pdd sync` command. The goal is to create a deterministic, reliable, and safe function that analyzes the state of a PDD unit (identified by a `basename` and `language`) and decides which PDD operation to run next.

This implementation will be a robust system based on file "fingerprints" and robust locking, as described below.

**Note**: This function analyzes a single language unit (basename + language). The sync_main function handles multiple language detection and orchestration. This function is called once per language by the orchestration layer.

### Core Principles:

1.  **Authoritative Fingerprints**: The system's state is not tracked in a complex state machine. Instead, it's derived by comparing the current state of files against a version-controlled "fingerprint" file that contains hashes of the last known good state from a PDD operation.
2.  **Robust Locking**: Use file-descriptor based locking (`fcntl` or `msvcrt`) to ensure that only one `pdd sync` process can operate on a given unit at a time, preventing race conditions. The lock must be re-entrant and handle stale lock files from crashed processes.
3.  **Deterministic Logic First**: Decisions must be made based on a clear, deterministic algorithm. An LLM should only be invoked for complex conflict resolution (e.g., when both the prompt and the code have changed), and its use must be made deterministic through caching.
4.  **Runtime Signal Integration**: The decision logic must be aware of the results from previous test runs. A failing test suite or a crashing program is a high-priority signal that should be addressed before proceeding with other operations.

### File and Directory Structure:

-   **Lock Files**: `.pdd/locks/{basename}_{language}.lock`
-   **Fingerprint Files**: `.pdd/meta/{basename}_{language}.json` (This file should be version controlled)
-   **Run Report Files**: `.pdd/meta/{basename}_{language}_run.json` (This file should be in `.gitignore`)

### Detailed Implementation Requirements:

#### 1. Data Structures

Create the following `dataclasses` to structure the data:

-   `Fingerprint`:
    -   `pdd_version: str`
    -   `timestamp: str` (ISO 8601 format)
    -   `command: str` (e.g., "generate", "fix")
    -   `prompt_hash: Optional[str]`
    -   `code_hash: Optional[str]`
    -   `example_hash: Optional[str]`
    -   `test_hash: Optional[str]`
-   `RunReport`:
    -   `timestamp: str`
    -   `exit_code: int`
    -   `tests_passed: int`
    -   `tests_failed: int`
    -   `coverage: float`
-   `SyncDecision`:
    -   `operation: str` (e.g., 'auto-deps', 'generate', 'example', 'crash', 'verify', 'test', 'fix', 'update', 'analyze_conflict', 'nothing')
    -   `reason: str` (A human-readable explanation for the decision)
    -   `details: Dict[str, Any]` (Optional extra info for the orchestrator)
    -   `estimated_cost: float` (Estimated cost for the operation, default 0.0)
    -   `confidence: float` (Confidence level in the decision, default 1.0)
    -   `prerequisites: List[str]` (List of operations that should be completed first)

#### 2. Locking Mechanism

Implement a `SyncLock` context manager:

-   `__init__(self, basename: str, language: str)`: Sets up the lock file path.
-   `acquire(self)`:
    -   Checks if the lock is already held by the current process (re-entrancy).
    -   If the lock file exists, read the PID.
    -   Use `psutil.pid_exists()` to check if the PID corresponds to a running process. If not, the lock is stale and should be removed.
    -   If the lock is held by another running process, raise a `TimeoutError`.
    -   Use `fcntl.flock` (POSIX) or `msvcrt.locking` (Windows) to acquire an exclusive, non-blocking lock on the file descriptor.
    -   Write the current PID to the lock file.
-   `release(self)`: Release the lock and delete the lock file.
-   The class should be usable as a context manager (`with SyncLock(...) as lock:`).

#### 3. State Analysis Functions

Implement the following helper functions:

-   `get_pdd_file_paths(basename: str, language: str) -> Dict[str, Path]`: Returns a dictionary mapping file types ('prompt', 'code', 'example', 'test') to their expected `pathlib.Path` objects. Use the project's internal `construct_paths` function (see included examples) to get configuration-aware paths. The function should:
    - Build the prompt file path from basename and language
    - Call `construct_paths` to get the output paths based on project configuration
    - Extract the code path from the returned `output_file_paths`
    - Derive example and test paths based on the code file location
-   `calculate_sha256(file_path: Path) -> Optional[str]`: Calculates the SHA256 hash of a file if it exists, otherwise returns `None`.
-   `read_fingerprint(basename: str, language: str) -> Optional[Fingerprint]`: Reads and validates the JSON fingerprint file. Returns `None` if it doesn't exist or is invalid.
-   `read_run_report(basename: str, language: str) -> Optional[RunReport]`: Reads and validates the JSON run report file.
-   `calculate_current_hashes(paths: Dict[str, Path]) -> Dict[str, Optional[str]]`: Computes the hashes for all current files on disk.

#### 4. The Main `sync_determine_operation` Function

This is the core function that orchestrates the decision-making process.

`sync_determine_operation(basename: str, language: str, target_coverage: float, budget: float = 10.0, log_mode: bool = False) -> SyncDecision:`

**Logic Flow:**

1.  **Acquire Lock**: Start by acquiring the `SyncLock` for the given unit. The entire function should operate within the `with` block of the lock. 

**Important**: When `log_mode=True`, skip lock acquisition entirely to avoid blocking other processes. This allows real-time state inspection without interfering with active sync operations:

```python
if log_mode:
    # Skip locking for read-only analysis
    return _perform_sync_analysis(basename, language, target_coverage, budget)
else:
    # Normal exclusive locking for actual operations
    with SyncLock(basename, language) as lock:
        return _perform_sync_analysis(basename, language, target_coverage, budget)
```

Log mode performs the complete analysis (reading fingerprints, calculating hashes, checking run reports, and applying decision logic) but without any file modifications or lock coordination.
2.  **Check Runtime Signals First**:
    -   Read the latest `RunReport`.
    -   If the report exists and `exit_code != 0`, return a decision to run `crash`.
    -   If `tests_failed > 0`, return a decision to run `fix`.
    -   If `coverage < target_coverage`, return a decision to run `test` to improve coverage.
    -   If any of these conditions are met, the analysis stops here, as fixing a broken state is the highest priority.
3.  **Analyze File State**:
    -   Read the last saved `Fingerprint`.
    -   Calculate the hashes of the current files.
    -   Compare the current hashes with the hashes in the fingerprint.
4.  **Implement the Decision Tree**:
    
    **Priority Order** (highest to lowest):
    1. Runtime failures (`crash`) - highest priority
    2. Test failures (`fix`) - second priority  
    3. Missing dependencies (`auto-deps`) - before generate
    4. Code generation (`generate`) - when prompt changed
    5. Example generation (`example`) - after code exists
    6. Verification (`verify`) - after example exists and doesn't crash
    7. Test generation (`test`) - after code verified
    8. Prompt updates (`update`) - when code changed
    9. Complex conflicts (`analyze_conflict`) - when multiple files changed
    
    -   **No Fingerprint (New or Untracked Unit):**
        -   If a `prompt` file exists:
            -   Check if prompt has `include` xml tags or references to other modules -> **`auto-deps`**. (Reason: Need to inject dependencies before generating).
            -   Otherwise -> **`generate`**. (Reason: A prompt is ready for a new unit).
        -   Otherwise -> **`nothing`**. (Reason: No prompt and no history means there's nothing to do).
    -   **No Changes (Hashes Match Fingerprint):**
        -   If `code` exists but `example` does not -> **`example`**. (Reason: Progress the workflow).
        -   If `code` and `example` exist but `test` does not -> **`test`**. (Reason: Progress the workflow).
        -   If all files exist and tests pass -> **`nothing`**. (Reason: All files are synchronized and the unit is complete).
    -   **Simple Changes (Single File Modified)**:
        -   If only the `prompt_hash` differs:
            -   Check if dependencies need updating -> **`auto-deps`**.
            -   Otherwise -> **`generate`**.
        -   If only the `code_hash` differs -> **`update`**.
        -   If only the `test_hash` differs -> **`test`** (to run the new tests).
        -   If only the `example_hash` differs -> **`verify`** (to run the new example).
    -   **Complex Changes (Multiple Files Modified / Conflicts)**:
        -   Return a decision to run **`analyze_conflict`**. The calling orchestrator will handle this.
5.  **Return the Decision**: The function must always return a `SyncDecision` object with the recommended operation and a clear reason.

#### 5. References: Here is how to use the internal modules that are available and must be used in this implementation:
    <internal_modules>
        For loading prompt templates:
        <load_prompt_template_example>
            <include>context/load_prompt_template_example.py</include>
        </load_prompt_template_example>

        For running prompts with llm_invoke:
        <llm_invoke_example>
            <include>context/llm_invoke_example.py</include>
        </llm_invoke_example>

        For path construction and configuration:
        <construct_paths_example>
            <include>context/construct_paths_example.py</include>
        </construct_paths_example>

        For language detection:
        <get_language_example>
            <include>context/get_language_example.py</include>
        </get_language_example>
    
        Here is the LLM prompt that will be used to analyze the conflict:
        <sync_analysis_LLM.prompt>
            <include>prompts/sync_analysis_LLM.prompt</include>
        </sync_analysis_LLM.prompt>

    Do not mock any of these internal modules. The real implementation of these modules is in the pdd/ directory and must be used in this implementation.
    </internal_modules>


% Here is the README.md that describes how how the sync command is used:
<README.md>
    <include>README.md</include>
</README.md>

Implement a second function `analyze_conflict_with_llm` to resolve complex sync conflicts using an LLM.

`analyze_conflict_with_llm(basename: str, language: str, fingerprint: Fingerprint, changed_files: List[str]) -> SyncDecision:`

**Logic Flow:**

1.  **Load LLM Prompt**: Use `load_prompt_template("sync_analysis_LLM")` to get the analysis prompt content.
2.  **Gather Diffs**: For each file type in `changed_files` ('prompt', 'code', 'test', 'example'), generate a `git diff` of the current file against its last committed version (`HEAD`). You will need a helper function for this (e.g., `get_git_diff(file_path)`). If a diff cannot be generated (e.g., file is not in git), use an empty string.
3.  **Format the Prompt**: Replace the placeholders in the loaded prompt template (`{fingerprint}`, `{changed_files_list}`, `{prompt_diff}`, etc.) with the actual data. The fingerprint should be formatted as a JSON string.
4.  **Invoke LLM**: Call `llm_invoke` with the fully formatted prompt. The call must be made deterministic by using a cache, ensuring that the same input always produces the same output recommendation.
5.  **Parse Response**: The LLM will respond with a JSON object. Parse this string into a dictionary.
6.  **Validate and Return**:
    -   Validate the JSON response to ensure it contains the required keys (`next_operation`, `reason`, etc.).
    -   If the LLM response is valid, construct and return a `SyncDecision` object based on the LLM's recommendation.
    -   If the LLM response is not valid JSON or if the confidence is low (e.g., < 0.75), return a default `fail_and_request_manual_merge` decision as a safety measure.

The final Python script should be well-structured with clear functions, type hints, and docstrings, containing all the logic described above.

### Integration with sync_orchestration

This function is called by sync_orchestration for each language. The orchestration layer:
1. Handles multiple language detection and iteration
2. Executes the recommended operations
3. Tracks cumulative costs and results
4. Manages the overall workflow loop
5. Handles budget constraints and maximum attempts

The sync_determine_operation function provides single-unit analysis while sync_orchestration handles the execution and multi-language coordination. The orchestration layer will:
- Call this function repeatedly as operations complete
- Track total cost against the budget parameter
- Stop if budget is exceeded or max attempts reached
- Handle the actual execution of operations (generate, test, fix, etc.)
- Update fingerprints and run reports after each operation

**Note on Implementation**: The orchestration layer may pass additional parameters (like `prompts_dir`) to help locate prompt files in different project structures. The `get_pdd_file_paths` function should be flexible enough to accept such parameters.

Define the PDD_DIR, META_DIR, LOCKS_DIR constants so that other modules can use them.