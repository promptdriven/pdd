# sync_determine_operation_python.prompt

You are an expert Python developer. Your task is to implement the core decision-making logic for the `pdd sync` command. The goal is to create a deterministic, reliable, and safe function that analyzes the state of a PDD unit (identified by a `basename` and `language`) and decides which PDD operation to run next.

This implementation must replace any previous complex state management with a more robust system based on file "fingerprints" and robust locking, as described below.

### Core Principles:

1.  **Authoritative Fingerprints**: The system's state is not tracked in a complex state machine. Instead, it's derived by comparing the current state of files against a version-controlled "fingerprint" file that contains hashes of the last known good state from a PDD operation.
2.  **Robust Locking**: Use file-descriptor based locking (`fcntl` or `msvcrt`) to ensure that only one `pdd sync` process can operate on a given unit at a time, preventing race conditions. The lock must be re-entrant and handle stale lock files from crashed processes.
3.  **Deterministic Logic First**: Decisions must be made based on a clear, deterministic algorithm. An LLM should only be invoked for complex conflict resolution (e.g., when both the prompt and the code have changed), and its use must be made deterministic through caching.
4.  **Runtime Signal Integration**: The decision logic must be aware of the results from previous test runs. A failing test suite or a crashing program is a high-priority signal that should be addressed before proceeding with other operations.

### File and Directory Structure:

-   **Lock Files**: `.pdd/locks/{basename}_{language}.lock`
-   **Fingerprint Files**: `.pdd/meta/{basename}_{language}.json` (This file should be version controlled)
-   **Run Report Files**: `.pdd/meta/{basename}_{language}_run.json` (This file should be in `.gitignore`)

### Detailed Implementation Requirements:

#### 1. Data Structures

Create the following `dataclasses` to structure the data:

-   `Fingerprint`:
    -   `pdd_version: str`
    -   `timestamp: str` (ISO 8601 format)
    -   `command: str` (e.g., "generate", "fix")
    -   `prompt_hash: Optional[str]`
    -   `code_hash: Optional[str]`
    -   `example_hash: Optional[str]`
    -   `test_hash: Optional[str]`
-   `RunReport`:
    -   `timestamp: str`
    -   `exit_code: int`
    -   `tests_passed: int`
    -   `tests_failed: int`
    -   `coverage: float`
-   `SyncDecision`:
    -   `operation: str` (e.g., 'generate', 'fix', 'update', 'test', 'crash', 'analyze_conflict', 'nothing')
    -   `reason: str` (A human-readable explanation for the decision)
    -   `details: Dict[str, Any]` (Optional extra info for the orchestrator)

#### 2. Locking Mechanism

Implement a `SyncLock` context manager:

-   `__init__(self, basename: str, language: str)`: Sets up the lock file path.
-   `acquire(self)`:
    -   Checks if the lock is already held by the current process (re-entrancy).
    -   If the lock file exists, read the PID.
    -   Use `psutil.pid_exists()` to check if the PID corresponds to a running process. If not, the lock is stale and should be removed.
    -   If the lock is held by another running process, raise a `TimeoutError`.
    -   Use `fcntl.flock` (POSIX) or `msvcrt.locking` (Windows) to acquire an exclusive, non-blocking lock on the file descriptor.
    -   Write the current PID to the lock file.
-   `release(self)`: Release the lock and delete the lock file.
-   The class should be usable as a context manager (`with SyncLock(...) as lock:`).

#### 3. State Analysis Functions

Implement the following helper functions:

-   `get_pdd_file_paths(basename: str, language: str) -> Dict[str, Path]`: Returns a dictionary mapping file types ('prompt', 'code', 'example', 'test') to their expected `pathlib.Path` objects. The implementation should use the project's internal configuration-aware functions (like `generate_output_paths`) rather than hardcoding directories to respect user configuration.
-   `calculate_sha256(file_path: Path) -> Optional[str]`: Calculates the SHA256 hash of a file if it exists, otherwise returns `None`.
-   `read_fingerprint(basename: str, language: str) -> Optional[Fingerprint]`: Reads and validates the JSON fingerprint file. Returns `None` if it doesn't exist or is invalid.
-   `read_run_report(basename: str, language: str) -> Optional[RunReport]`: Reads and validates the JSON run report file.
-   `calculate_current_hashes(paths: Dict[str, Path]) -> Dict[str, Optional[str]]`: Computes the hashes for all current files on disk.

#### 4. The Main `determine_sync_operation` Function

This is the core function that orchestrates the decision-making process.

`determine_sync_operation(basename: str, language: str, target_coverage: float) -> SyncDecision:`

**Logic Flow:**

1.  **Acquire Lock**: Start by acquiring the `SyncLock` for the given unit. The entire function should operate within the `with` block of the lock.
2.  **Check Runtime Signals First**:
    -   Read the latest `RunReport`.
    -   If the report exists and `exit_code != 0`, return a decision to run `crash`.
    -   If `tests_failed > 0`, return a decision to run `fix`.
    -   If `coverage < target_coverage`, return a decision to run `test` to improve coverage.
    -   If any of these conditions are met, the analysis stops here, as fixing a broken state is the highest priority.
3.  **Analyze File State**:
    -   Read the last saved `Fingerprint`.
    -   Calculate the hashes of the current files.
    -   Compare the current hashes with the hashes in the fingerprint.
4.  **Implement the Decision Tree**:
    -   **No Fingerprint (New or Untracked Unit):**
        -   If a `prompt` file exists -> **`generate`**. (Reason: A prompt is ready for a new unit).
        -   Otherwise -> **`nothing`**. (Reason: No prompt and no history means there's nothing to do).
    -   **No Changes (Hashes Match Fingerprint):**
        -   If `code` exists but `example` does not -> **`example`**. (Reason: Progress the workflow).
        -   If `code` and `example` exist but `test` does not -> **`test`**. (Reason: Progress the workflow).
        -   Otherwise -> **`nothing`**. (Reason: All files are synchronized and the unit is complete).
    -   **Simple Changes (Single File Modified)**:
        -   If only the `prompt_hash` differs -> `generate`.
        -   If only the `code_hash` differs -> `update`.
        -   If only the `test_hash` differs -> `test` (to run the new tests).
        -   If only the `example_hash` differs -> `verify` (to run the new example).
    -   **Complex Changes (Multiple Files Modified / Conflicts)**:
        -   Return a decision to run **`analyze_conflict`**. The calling orchestrator will handle this.
5.  **Return the Decision**: The function must always return a `SyncDecision` object with the recommended operation and a clear reason.

#### 5. LLM-based Conflict Analysis

% Here is how to use the internal modules:
    <internal_modules>
        For loading prompt templates:
        <load_prompt_template_example>
            <include>context/load_prompt_template_example.py</include>
        </load_prompt_template_example>

        For running prompts with llm_invoke:
        <llm_invoke_example>
            <include>context/llm_invoke_example.py</include>
        </llm_invoke_example>
    

Implement a second function `analyze_conflict_with_llm` to resolve complex sync conflicts using an LLM.

`analyze_conflict_with_llm(basename: str, language: str, fingerprint: Fingerprint, changed_files: List[str]) -> SyncDecision:`

**Logic Flow:**

1.  **Load LLM Prompt**: Use `load_prompt_template("sync_analysis_LLM.prompt")` to get the analysis prompt content.
2.  **Gather Diffs**: For each file type in `changed_files` ('prompt', 'code', 'test', 'example'), generate a `git diff` of the current file against its last committed version (`HEAD`). You will need a helper function for this (e.g., `get_git_diff(file_path)`). If a diff cannot be generated (e.g., file is not in git), use an empty string.
3.  **Format the Prompt**: Replace the placeholders in the loaded prompt template (`{fingerprint}`, `{changed_files_list}`, `{prompt_diff}`, etc.) with the actual data. The fingerprint should be formatted as a JSON string.
4.  **Invoke LLM**: Call `llm_invoke` with the fully formatted prompt. The call must be made deterministic by using a cache, ensuring that the same input always produces the same output recommendation.
5.  **Parse Response**: The LLM will respond with a JSON object. Parse this string into a dictionary.
6.  **Validate and Return**:
    -   Validate the JSON response to ensure it contains the required keys (`next_operation`, `reason`, etc.).
    -   If the LLM response is valid, construct and return a `SyncDecision` object based on the LLM's recommendation.
    -   If the LLM response is not valid JSON or if the confidence is low (e.g., < 0.75), return a default `fail_and_request_manual_merge` decision as a safety measure.

The final Python script should be well-structured with clear functions, type hints, and docstrings, containing all the logic described above.
