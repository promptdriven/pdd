% Write function "fix_verification_errors_loop" that iteratively fixes code errors by comparing program execution output against the original prompt's intent, with hybrid cloud support for LLM calls.

<include>context/python_preamble.prompt</include>

% Signature:
def fix_verification_errors_loop(
    program_file: str,           # Python program exercising code_file
    code_file: str,              # Code being verified/fixed
    prompt: str,                 # Prompt defining intended behavior
    prompt_file: str,            # Path to prompt file (for agentic fallback)
    verification_program: str,   # Secondary verification program (must exist)
    strength: float,             # [0,1] LLM model strength
    temperature: float,          # [0,1] LLM temperature
    max_attempts: int,           # Max fix attempts
    budget: float,               # Max cost allowed
    verification_log_file: str = "verification.log",
    output_code_path: Optional[str] = None,
    output_program_path: Optional[str] = None,
    verbose: bool = False,
    program_args: Optional[list[str]] = None,
    llm_time: float = DEFAULT_TIME,
    agentic_fallback: bool = True,
    use_cloud: bool = False,     # Hybrid cloud: LLM calls via cloud verifyCode endpoint, local program execution
) -> Dict[str, Any]:  # Returns: success, final_program, final_code, total_attempts, total_cost, model_name, statistics

% Dependencies:
<fix_verification_errors_example>
    <include>context/fix_verification_errors_example.py</include>
</fix_verification_errors_example>
<agentic_verify_example><include>context/agentic_verify_example.py</include></agentic_verify_example>
<agentic_langtest_example><include>context/agentic_langtest_example.py</include></agentic_langtest_example>
<get_language_example><include>context/get_language_example.py</include></get_language_example>

% Helpers:
  - `cloud_verify_fix(program, prompt, code, output, strength, temperature, time_param, verbose, language)`: Call cloud verifyCode endpoint for LLM verification fix. Returns dict with fixed_code, fixed_program, explanation, verification_issues_count, total_cost, model_name. Falls back to local on cloud failure.

% Algorithm:
1. Non-Python targets (.py check): bypass loop, use get_language()/default_verify_cmd_for(), invoke run_agentic_verify
2. Validate inputs (files exist, params in range); return failure with empty statistics if invalid
3. Initial assessment: run program_file, call fix_verification_errors
   - Abort on error sentinel (explanation=None AND model_name=None)
   - Return success if verification_issues_count == 0; return failure if budget exceeded
4. Main loop (attempts < max_attempts, budget not exceeded):
   - Run program, backup files, call fix_verification_errors
   - If code changed: run verification_program; apply if passes, discard if fails
   - Track best iteration (lowest issues where verification passed)
   - Break on success (0 issues + verified) or no effective changes
5. Final: return success if any verification passed; else restore best/original state
6. Agentic fallback: if failed and agentic_fallback=True, invoke run_agentic_verify with `cwd=Path(prompt_file).parent` to ensure paths resolve correctly

% XML Logging (xml.sax.saxutils.escape):
<InitialState>, <Iteration attempt="N"> (with <SecondaryVerification passed="true/false">), <FinalActions>

% Deliverables:
Implement to pass all tests in tests/test_fix_verification_errors_loop.py. Include helpers for subprocess execution and log writing.
