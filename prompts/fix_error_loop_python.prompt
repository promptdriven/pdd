% You are an expert Python Software Engineer. Write a module containing the `fix_error_loop` function that implements an iterative, agentic workflow to fix errors in unit tests and code using an LLM.

### Role and Scope:
Core execution engine for automated code-repair. Manages fix attempt lifecycle: run tests, capture failures, invoke LLM for repairs, verify, and fall back to agentic fix if the loop fails. Handles state management (backups/restoration) and detailed logging.

### Requirements:
1.  **Iterative Fixing:** `fix_error_loop` resolves code/test mismatches over multiple iterations (up to `max_attempts`), tracking failures, errors, and warnings.
2.  **Statistics & Improvement:** Maintain a `stats` dictionary tracking initial/final states, improvement percentages, and `best_iteration`.
3.  **Structured XML Logging:** Dictionary-based log formatted into XML tags (`<pytest_output>`, `<fix_attempt>`, `<verification_output>`) per iteration, written to `error_log_file`.
4.  **Best State Recovery:** If final iteration isn't best (prioritize: lowest errors → fails → warnings), restore from best iteration backups.
5.  **Verification Step:** After code updates, run verification via `detect_host_python_executable`. On non-zero exit, restore backup and log restoration.
6.  **Agentic Fallback:** If loop fails and budget remains, invoke `run_agentic_fix`. Ensure `error_log_file` is populated before agent call.
7.  **Non-Python Support:** Detect by extension, use `default_verify_cmd_for` for initial verification. If it fails, skip pytest loop and go directly to agentic fallback.
8.  **Budget Management:** Accumulate `total_cost` from LLM calls; stop immediately if `budget` exceeded.
9.  **Output Contract:** Return 6-tuple: `(success, final_unit_test, final_code, total_attempts, total_cost, model_name)`.
    *   If tests pass initially: return actual file contents, `0` attempts, `0.0` cost, empty model name.
10. **Result Normalization:** `_normalize_agentic_result` handles 2/3/4/5-tuple returns from agentic fix, extracting `changed_files` if available.

### Public Interface:

```python
def fix_error_loop(
    unit_test_file: str,
    code_file: str,
    prompt_file: str,
    prompt: str,
    verification_program: str,
    strength: float,
    temperature: float,
    max_attempts: int,
    budget: float,
    error_log_file: str = "error_log.txt",
    verbose: bool = False,
    time: float = DEFAULT_TIME,
    agentic_fallback: bool = True
) -> tuple[bool, str, str, int, float, str]:
    """Returns: (success, final_unit_test, final_code, total_attempts, total_cost, model_name)"""
```

### Internal Data Structures:

**`stats` dictionary:**
```python
stats = {
    "initial_fails": int, "initial_errors": int, "initial_warnings": int,
    "final_fails": int, "final_errors": int, "final_warnings": int,
    "best_iteration": int | str | None,  # iteration number, "final", or 0
    "iterations_info": list,
    "improvement": {"fails_reduced": int, "errors_reduced": int, "warnings_reduced": int, "percent_improvement": float}
}
```

**`_normalize_agentic_result` mapping:**
| Input | Output |
|-------|--------|
| 5-tuple | `(success, msg, cost, model, changed_files)` directly |
| 4-tuple | add `changed_files=[]` |
| 3-tuple | add `model="agentic-cli"`, `changed_files=[]` |
| 2-tuple | add `cost=0.0`, `model="agentic-cli"`, `changed_files=[]` |

Returns: `(bool, str, float, str, List[str])`

### Control Flow:

```mermaid
stateDiagram-v2
    [*] --> Init: validate files exist
    Init --> InitialTest: run pytest or verify cmd
    InitialTest --> NonPythonFallback: non-Python && fails
    InitialTest --> NonPythonPass: non-Python && passes
    InitialTest --> FixLoop: Python (always enters loop)

    state FixLoop {
        [*] --> CheckSuccess
        CheckSuccess --> ReadFiles_InLoop: success=true (break, read files HERE)
        CheckSuccess --> CreateBackups: success=false
        CreateBackups --> UpdateBestIteration
        UpdateBestIteration --> CallLLMFix
        CallLLMFix --> IncrementAttempts: fix_attempts++
        IncrementAttempts --> WriteFiles
        WriteFiles --> RunVerification
        RunVerification --> RestoreBackup: verification fails
        RestoreBackup --> RerunPytest
        RunVerification --> RerunPytest: verification passes
        RerunPytest --> CheckSuccess
    }

    FixLoop --> PostLoop
    PostLoop --> RestoreBest: !success && best_attempt!=None
    PostLoop --> SetFinal: success OR best_attempt==None
    RestoreBest --> ReadFiles_PostLoop
    SetFinal --> ReadFiles_PostLoop: stats["best_iteration"]="final"
    ReadFiles_PostLoop --> PrintSummary: skip read if initially_passing
    PrintSummary --> AgenticFallback: !success && budget remains
    PrintSummary --> Return: success
    AgenticFallback --> Return
    NonPythonFallback --> Return
    NonPythonPass --> Return
    Return --> [*]
```

Notes:
- ALL Python files enter FixLoop (even initially-passing)
- Initially-passing: CheckSuccess → ReadFiles_InLoop → break → PostLoop → SetFinal
- `fix_attempts` counts LLM calls, not loop iterations
- PostLoop skips file read for initially_passing (already read in loop)

### Dependencies:
<python_preamble>
    <include>context/python_preamble.prompt</include>
</python_preamble>
<internal_modules>
    <get_language>
        <include>context/get_language_example.py</include>
    </get_language>
    <fix_errors_from_unit_tests>
        <include>context/fix_errors_from_unit_tests_example.py</include>
    </fix_errors_from_unit_tests>
    <agentic_fix>
        <include>context/agentic_fix_example.py</include>
    </agentic_fix>
    <agentic_langtest>
        <include>context/agentic_langtest_example.py</include>
    </agentic_langtest>
    <pytest_output>
        <include>context/pytest_example.py</include>
    </pytest_output>
    <python_env_detector>
        <include>context/python_env_detector.py</include>
    </python_env_detector>
</internal_modules>

### Instructions:
1.  **`run_pytest_on_file(test_file)`**: Use `run_pytest_and_capture_output`. Extract failures/errors/warnings from first JSON result. Combine `standard_output` and `standard_error` for log.
2.  **`format_log_for_output(log_structure)`**: Convert iteration list to string with XML tags and `iteration=n` attributes. First iteration includes initial test output.
3.  **`fix_error_loop`**:
    *   **Init**: Setup stats, best iteration tracker (use `sys.maxsize` for comparison), structured log.
    *   **Initial Check**: Run pytest (or verify for non-Python). Exit early if passing per output contract.
    *   **Loop**: Create timestamped backups (`filename_iter_err_fail_warn_timestamp.ext`), call `fix_errors_from_unit_tests` with `formatted_log`, update files, verify, re-run pytest.
    *   **Finalize**: Compare final to best iteration, restore if needed. Print `rich` summary with percentage reduction.
4.  **Agentic Fallback**: `_safe_run_agentic_fix` calls agent and normalizes result. Ensure `error_log_file` written before call. If no iterations ran, write initial state. Log `agent_changed_files` to console.
5.  **Console Output**: Use `rich.print` as `rprint`. Implement `escape_brackets` helper to prevent Rich from parsing square brackets.

### Deliverables:
*   Standalone Python file with `run_pytest_on_file`, `format_log_for_output`, `fix_error_loop`, and normalization helpers.
*   Include `if __name__ == "__main__":` block with sample execution using mock parameters.
