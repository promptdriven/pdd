% You are an expert Python Software Engineer. Your goal is to write a Python function, "fix_error_loop", that will attempt to fix errors in a unit test and its corresponding code file through multiple iterations. The function should include an optional verbose mode for detailed logging.

<include>context/python_preamble.prompt</include>

% Here are the inputs and outputs of the function:
    Inputs: 
        'unit_test_file' - A string containing the path to the unit test file.
        'code_file' - A string containing the path to the code file being tested.
        'prompt' - A string containing the prompt that generated the code under test.
        'verification_program' - A string containing the path to a Python program that verifies if the code still runs correctly.
        'strength' - A float between or equal to 0 and 1 that represents the strength of the LLM model to use.
        'temperature' - A float between or equal to 0 and 1 that represents the temperature parameter for the LLM model.
        'max_attempts' - An integer representing the maximum number of fix attempts before giving up.
        'budget' - A float representing the maximum cost allowed for the fixing process.
        'error_log_file' - A string containing the path to the error log file (default: "error_log.txt").
        'verbose' - A boolean indicating whether to enable verbose logging (default: False).
    Outputs:
        'success' - A boolean indicating whether the errors were successfully fixed.
        'final_unit_test' - A string containing the contents of the final unit test file.
        'final_code' - A string containing the contents of the final code file.
        'total_attempts' - An integer representing the number of fix attempts made.
        'total_cost' - A float representing the total cost of all fix attempts.
        'model_name' - A string representing the name of the LLM model used.

% Here are examples of how to use internal modules:
<internal_example_modules>
    % Here is an example of the fix_errors_from_unit_tests function that will be used: <fix_errors_from_unit_tests_example><include>context/fix_errors_from_unit_tests_example.py</include></fix_errors_from_unit_tests_example>
</internal_example_modules>

% Here is an example of the TestResultCollector plugin used to capture pytest results:
<pytest_result_collector_example>
    <include>context/pytest_example.py</include>
</pytest_result_collector_example>

% This function will do the following:
    Step 1. Remove the existing error log file specified by 'error_log_file' if it exists.
    Step 2. Initialize variables:
        - Counter for the number of attempts
        - Total cost accumulator
        - Best iteration tracker (This is so that in case not all issues are solved, the iteration with the lowest errors get restored. In case there are iterations with the same number errors, then the iteration with the lowest fails, then the lowest warnings will get restored.)
    Step 3. Enter a while loop that continues until max_attempts is reached or budget is exceeded:
        a. Print out to console and error log file the attempt iteration
        b. Run the unit tests using pytest's API directly with a custom TestResultCollector plugin that captures:
           - Number of failures (tests that failed assertions)
           - Number of errors (tests that had errors during setup, execution, or teardown)
           - Number of warnings
           - Complete test output logs
        c. If the test passes and has no warnings, break the loop.
        d. If the test fails or has warnings:
           - Print the captured test output to the console and error log file, escaping square brackets for proper Rich console display
           - Create backup copies of the unit_test_file and code_file in their respective directories, appending the current iteration number, the number of errors, fails, and warnings to the filenames like this "unit_test_filename_3_1_0_2.py" and "code_filename_3_1_0_2.py", it is the third iteration where there was one error, zero fails, and two warnings through the loop.
           - Read the contents of the unit_test_file and code_file.
           - Call fix_errors_from_unit_tests with the file contents, error and warning messages from the error log file, the error log file, and the provided strength and temperature. Pass the verbose flag to enable detailed logging if specified.
           - Add the returned total_cost to the total cost accumulator.
           - If the total cost exceeds the budget, break the loop.
           - If both updated_unit_test and updated_code are False, break the loop as no changes were needed.
           - If updated_unit_test is True, write the fixed_unit_test back to the unit_test_file.
           - Increment the attempt counter.
           - If updated_code is True:
              * Write the fixed_code back to the code_file.
              * Run the verification_program to check if the code still runs.
              * If the verification fails, restore the last known working code_file from one of the backups and output the errors and results of the failed verification run into the error log file so that this can be debugged in the next iteration and indicate that a restore has happened. Then continue the loop. 
              * If the verification succeeds, update the best iteration tracker if this iteration has fewer errors or fails.
           - Run the tests again in the same iteration using the pytest API to check if the fixes worked
    Step 4. After the loop ends, run pytest one final time using the API, append the output to the error log file, escape square brackets and print it to the console.
    Step 5. If the last run isn't the best iteration, copy back the files from the best iteration and print out which was the best iteration.
    Step 6. Return the success status, final unit test contents, final code contents, total number of attempts, and total cost.
