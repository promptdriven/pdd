<!DOCTYPE html>
<html>
<head>
    <title>Hand Tracking Drawing App</title>
    <meta charset="utf-8">
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; display: flex; justify-content: center; align-items: center; height: 100vh; }
        #videoElement {
            display: none; /* Hidden as it's rendered onto the canvas via Three.js */
        }
        #outputCanvas {
            width: 640px; /* Default, will be adjusted */
            height: 480px; /* Default, will be adjusted */
            border: 1px solid white;
        }
        /* Ensure video is unmirrored if directly visible (not strictly needed here as it's a texture) */
        .unmirrored {
            transform: scaleX(1);
        }
    </style>
</head>
<body>
    <video id="videoElement" class="unmirrored" playsinline style="display: none;"></video>
    <canvas id="outputCanvas"></canvas>

    <!-- MediaPipe Hands -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>

    <!-- Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js" crossorigin="anonymous"></script>

    <script type="module">
        // --- Global Variables ---
        const videoElement = document.getElementById('videoElement');
        const outputCanvas = document.getElementById('outputCanvas');
        let videoWidth, videoHeight;

        let scene, camera, renderer, videoTexture;
        let hands;

        // Drawing states
        let currentMode = 'none'; // 'draw', 'erase', 'none'
        let currentStrokePoints = [];
        let allStrokes = []; // Stores THREE.Line objects
        let handSkeletonLines = new THREE.Group(); // Group to hold skeleton lines
        let palmCenterDot;
        const ERASE_RADIUS = 15; // Pixel radius for erasing
        const DRAW_COLOR = 0xff0000; // Red
        const SKELETON_COLOR = 0x00ff00; // Green
        const PALM_DOT_COLOR = 0x0000ff; // Blue

        // --- Initialization ---
        async function main() {
            // 1. Webcam Access and Video Initialization (unmirrored)
            // Where and how the webcam is accessed and the <video> element is initialized unmirrored.
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'user' }
                });
                videoElement.srcObject = stream;
                videoElement.onloadedmetadata = () => {
                    videoElement.play();
                    videoWidth = videoElement.videoWidth;
                    videoHeight = videoElement.videoHeight;
                    outputCanvas.width = videoWidth;
                    outputCanvas.height = videoHeight;
                    
                    // Initialize MediaPipe and Three.js after video dimensions are known
                    setupMediaPipe();
                    setupThreeJS();
                    
                    requestAnimationFrame(renderLoop);
                };
            } catch (err) {
                console.error("Error accessing webcam:", err);
                alert("Could not access webcam. Please ensure permissions are granted.");
            }
        }

        // 2. MediaPipe Hands Initialization
        // Where MediaPipe Hands is initialized and how landmarks are used.
        function setupMediaPipe() {
            hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({
                maxNumHands: 1,
                modelComplexity: 1,
                minDetectionConfidence: 0.7,
                minTrackingConfidence: 0.7
            });
            hands.onResults(onHandResults);
        }

        // 5. Three.js Initialization
        // Where the Three.js renderer is configured.
        function setupThreeJS() {
            scene = new THREE.Scene();

            // Use video dimensions for orthographic camera to map 1:1 with video pixels
            // (0,0) will be top-left
            camera = new THREE.OrthographicCamera(0, videoWidth, 0, videoHeight, -1000, 1000);
            camera.position.set(videoWidth / 2, videoHeight / 2, 500); // Centered
            camera.lookAt(videoWidth / 2, videoHeight / 2, 0);
            // Adjust camera to make (0,0) top-left and Y-axis point downwards
            camera.left = 0;
            camera.right = videoWidth;
            camera.top = 0;
            camera.bottom = videoHeight;
            camera.updateProjectionMatrix();


            renderer = new THREE.WebGLRenderer({ canvas: outputCanvas, alpha: true });
            renderer.setSize(videoWidth, videoHeight);
            renderer.setClearColor(0x000000, 0); // Transparent background

            // Use video as texture for the scene background
            videoTexture = new THREE.VideoTexture(videoElement);
            scene.background = videoTexture;

            // Palm center dot (eraser indicator)
            const dotGeometry = new THREE.CircleGeometry(ERASE_RADIUS / 2, 32);
            const dotMaterial = new THREE.MeshBasicMaterial({ color: PALM_DOT_COLOR });
            palmCenterDot = new THREE.Mesh(dotGeometry, dotMaterial);
            palmCenterDot.visible = false;
            scene.add(palmCenterDot);

            scene.add(handSkeletonLines);
        }

        // --- Real-time Processing Loop ---
        function renderLoop() {
            if (videoElement.readyState >= videoElement.HAVE_METADATA && !videoElement.paused) {
                hands.send({ image: videoElement });
            }
            // Update video texture
            if (videoTexture) videoTexture.needsUpdate = true;
            
            renderer.render(scene, camera);
            requestAnimationFrame(renderLoop);
        }

        // --- MediaPipe Hand Results Callback ---
        function onHandResults(results) {
            // Clear previous skeleton
            while(handSkeletonLines.children.length > 0){ 
                const obj = handSkeletonLines.children[0];
                handSkeletonLines.remove(obj);
                if(obj.geometry) obj.geometry.dispose();
                if(obj.material) obj.material.dispose();
            }

            palmCenterDot.visible = false;

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmarks = results.multiHandLandmarks[0]; // Assuming one hand
                
                // Convert landmarks to Three.js coordinates
                // All gesture-based coordinates (skeleton lines, palm-dot, drawing strokes) 
                // correspond to the unmirrored camera orientation.
                const worldLandmarks = landmarks.map(lm => {
                    return new THREE.Vector3(
                        lm.x * videoWidth,
                        lm.y * videoHeight, // Y is already top-down from MediaPipe
                        (lm.z + 0.5) * -videoWidth * 0.5 // Approximate Z, make it negative to be in front
                    );
                });

                // Draw hand skeleton
                drawHandSkeleton(worldLandmarks, HAND_CONNECTIONS);

                // Where the code decides between “draw” (index finger) vs. “erase” (open palm) modes
                const newMode = getGestureMode(landmarks); // Use normalized for gesture logic

                if (currentMode === 'draw' && newMode !== 'draw') {
                    finishCurrentStroke();
                }
                currentMode = newMode;

                const palmCenterLandmark = worldLandmarks[9]; // Using middle finger MCP as palm center proxy

                if (currentMode === 'draw') {
                    palmCenterDot.visible = false;
                    const indexFingerTip = worldLandmarks[8];
                    if (currentStrokePoints.length === 0 || 
                        currentStrokePoints[currentStrokePoints.length - 1].distanceTo(indexFingerTip) > 2) { // Add point if moved enough
                        currentStrokePoints.push(indexFingerTip.clone());
                        updateLiveStroke();
                    }
                } else if (currentMode === 'erase') {
                    palmCenterDot.position.copy(palmCenterLandmark);
                    palmCenterDot.position.z = 10; // Ensure dot is visible
                    palmCenterDot.visible = true;
                    // Where the Three.js renderer is configured to draw and erase line segments under the palm dot.
                    eraseSegmentsNear(palmCenterLandmark);
                } else { // 'none'
                    palmCenterDot.visible = false;
                }
            } else { // No hand detected
                if (currentMode === 'draw') {
                    finishCurrentStroke();
                }
                currentMode = 'none';
                palmCenterDot.visible = false;
            }
        }

        // --- Gesture Detection ---
        // Where MediaPipe Hands landmarks are used to position the skeleton and palm-center dot.
        // And where the code decides between “draw” (index finger) vs. “erase” (open palm) modes.
        function getGestureMode(landmarks) {
            // Simple gesture detection (normalized landmarks 0-1)
            // Index finger extended: tip (8) is further "up" (smaller y) than knuckle (5)
            const indexTipY = landmarks[8].y;
            const indexKnuckleY = landmarks[5].y;
            const indexPipY = landmarks[6].y;

            // Other fingers curled: tips (12, 16, 20) are "down" (larger y) than their PIP joints (10, 14, 18)
            const middleTipY = landmarks[12].y;
            const middlePipY = landmarks[10].y;
            const ringTipY = landmarks[16].y;
            const ringPipY = landmarks[14].y;
            const pinkyTipY = landmarks[20].y;
            const pinkyPipY = landmarks[18].y;

            const isIndexPointing = indexTipY < indexPipY && indexPipY < indexKnuckleY &&
                                    middleTipY > middlePipY &&
                                    ringTipY > ringPipY &&
                                    pinkyTipY > pinkyPipY;

            if (isIndexPointing) return 'draw';

            // Open palm: all fingertips (8,12,16,20) are extended
            const isIndexExtended = indexTipY < indexPipY;
            const isMiddleExtended = middleTipY < middlePipY;
            const isRingExtended = ringTipY < ringPipY;
            const isPinkyExtended = pinkyTipY < pinkyPipY;
            
            // Check thumb is somewhat out (landmark 4.x vs 2.x for right hand, reverse for left)
            // This is a rough check and might need adjustment based on hand orientation
            const thumbTipX = landmarks[4].x;
            const thumbBaseX = landmarks[2].x; // A point near thumb base
            // Assuming right hand for now, if thumbTipX is less than thumbBaseX, it's likely open
            // A more robust check would involve handedness or more complex relations
            const isThumbOpen = Math.abs(landmarks[4].y - landmarks[17].y) > Math.abs(landmarks[4].x - landmarks[17].x) * 0.3; // Thumb is somewhat away from pinky base

            if (isIndexExtended && isMiddleExtended && isRingExtended && isPinkyExtended && isThumbOpen) {
                return 'erase';
            }
            
            return 'none';
        }

        // --- Drawing and Erasing Logic ---
        let liveStrokeLine = null;
        function updateLiveStroke() {
            if (liveStrokeLine) {
                scene.remove(liveStrokeLine);
                liveStrokeLine.geometry.dispose();
                liveStrokeLine.material.dispose();
                liveStrokeLine = null;
            }
            if (currentStrokePoints.length > 1) {
                const geometry = new THREE.BufferGeometry().setFromPoints(currentStrokePoints);
                const material = new THREE.LineBasicMaterial({ color: DRAW_COLOR, linewidth: 3 }); // Linewidth might not be respected on all systems
                liveStrokeLine = new THREE.Line(geometry, material);
                liveStrokeLine.position.z = 5; // Ensure drawing is visible
                scene.add(liveStrokeLine);
            }
        }

        function finishCurrentStroke() {
            if (liveStrokeLine) { // Add the finalized live stroke
                 allStrokes.push(liveStrokeLine);
                 liveStrokeLine = null; // It's now part of allStrokes
            }
            currentStrokePoints = [];
        }
        
        // Where the code erases line segments under the palm dot.
        function eraseSegmentsNear(eraseCenter) {
            const newAllStrokes = [];
            for (let i = allStrokes.length - 1; i >= 0; i--) {
                const stroke = allStrokes[i];
                const originalPoints = Array.from(stroke.geometry.attributes.position.array)
                    .reduce((acc, val, idx, arr) => {
                        if (idx % 3 === 0) acc.push(new THREE.Vector3(arr[idx], arr[idx+1], arr[idx+2]));
                        return acc;
                    }, []);

                if (originalPoints.length < 2) {
                    scene.remove(stroke);
                    stroke.geometry.dispose();
                    stroke.material.dispose();
                    continue; 
                }

                let currentSegmentCollection = [];
                const survivingStrokeParts = []; // Stores arrays of points for new strokes

                // Start with the first point, assuming it's not erased initially
                // This simplifies logic for the first segment.
                if (originalPoints[0].distanceTo(eraseCenter) > ERASE_RADIUS) {
                     currentSegmentCollection.push(originalPoints[0].clone());
                }


                for (let j = 0; j < originalPoints.length - 1; j++) {
                    const p1 = originalPoints[j];
                    const p2 = originalPoints[j+1];
                    
                    // Check if segment (p1,p2) intersects the erase circle
                    const segmentHit = isSegmentIntersectingCircle(p1, p2, eraseCenter, ERASE_RADIUS);

                    if (segmentHit) {
                        if (currentSegmentCollection.length > 1) {
                            survivingStrokeParts.push(currentSegmentCollection);
                        }
                        currentSegmentCollection = []; // Start a new collection for points after the erased segment
                    } else { // Segment not hit
                        // If currentSegmentCollection is empty, it means the previous segment was hit.
                        // So, p1 is the start of a new un-erased segment.
                        if (currentSegmentCollection.length === 0) {
                            currentSegmentCollection.push(p1.clone());
                        }
                        currentSegmentCollection.push(p2.clone());
                    }
                }
                
                if (currentSegmentCollection.length > 1) {
                    survivingStrokeParts.push(currentSegmentCollection);
                }

                // Remove old stroke and add new ones
                scene.remove(stroke);
                stroke.geometry.dispose();
                stroke.material.dispose();

                survivingStrokeParts.forEach(points => {
                    if (points.length > 1) {
                        const geometry = new THREE.BufferGeometry().setFromPoints(points);
                        const material = new THREE.LineBasicMaterial({ color: DRAW_COLOR, linewidth: 3 });
                        const newStroke = new THREE.Line(geometry, material);
                        newStroke.position.z = 5;
                        scene.add(newStroke);
                        newAllStrokes.push(newStroke);
                    }
                });
            }
            allStrokes = newAllStrokes;
        }

        function isSegmentIntersectingCircle(p1, p2, C, R) {
            // Check if endpoints are inside
            if (p1.distanceTo(C) < R || p2.distanceTo(C) < R) return true;

            // Check distance from C to line segment p1-p2
            const p1_p2 = new THREE.Vector3().subVectors(p2, p1);
            const C_p1 = new THREE.Vector3().subVectors(C, p1);
            
            const lenSq_p1_p2 = p1_p2.lengthSq();
            if (lenSq_p1_p2 === 0) return p1.distanceTo(C) < R; // p1 and p2 are same point

            // Project C_p1 onto p1_p2
            // t = dot(C_p1, p1_p2) / |p1_p2|^2
            let t = C_p1.dot(p1_p2) / lenSq_p1_p2;
            t = Math.max(0, Math.min(1, t)); // Clamp t to [0,1] for segment

            const closestPointOnSegment = new THREE.Vector3().copy(p1).addScaledVector(p1_p2, t);
            return closestPointOnSegment.distanceTo(C) < R;
        }


        // --- Helper to draw skeleton ---
        // Where MediaPipe Hands landmarks are used to position the skeleton.
        function drawHandSkeleton(worldLandmarks, connections) {
            if (!worldLandmarks || worldLandmarks.length === 0) return;

            connections.forEach(conn => {
                const start = worldLandmarks[conn[0]];
                const end = worldLandmarks[conn[1]];
                if (start && end) {
                    const points = [start, end];
                    const geometry = new THREE.BufferGeometry().setFromPoints(points);
                    const material = new THREE.LineBasicMaterial({ color: SKELETON_COLOR, linewidth: 2 });
                    const line = new THREE.Line(geometry, material);
                    line.position.z = 1; // Ensure skeleton is visible
                    handSkeletonLines.add(line);
                }
            });
        }
        
        main();

    </script>
</body>
</html>