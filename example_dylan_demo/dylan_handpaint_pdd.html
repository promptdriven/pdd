<!DOCTYPE html>
<html>
<head>
    <title>Hand Tracking Drawing</title>
    <meta charset="utf-8">
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }
        /* The video element is used as a source for textures, not displayed directly. */
        #videoElement {
            display: none;
        }
        /* Helper canvases for MediaPipe and drawing layer, not displayed directly. */
        #skeletonCanvas, #drawingLayerCanvas {
            display: none;
        }
        /* Canvas where Three.js renders. This will be styled to fill the viewport. */
        #threeCanvas {
            width: 100vw;
            height: 100vh;
            object-fit: contain; /* Or 'cover', depending on desired aspect ratio handling */
        }
    </style>
    <!-- MediaPipe Hands and Drawing Utils -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <!-- Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <video id="videoElement" autoplay playsinline></video>
    <canvas id="skeletonCanvas"></canvas>
    <canvas id="drawingLayerCanvas"></canvas>
    <!-- Three.js will render to this canvas -->
    <canvas id="threeCanvas"></canvas>

    <script type="module">
        // --- Global Variables and Constants ---
        const videoElement = document.getElementById('videoElement');
        const skeletonCanvas = document.getElementById('skeletonCanvas');
        const skeletonCtx = skeletonCanvas.getContext('2d');
        const drawingLayerCanvas = document.getElementById('drawingLayerCanvas');
        const drawingCtx = drawingLayerCanvas.getContext('2d');
        const threeCanvas = document.getElementById('threeCanvas');

        let scene, camera, renderer;
        let videoTexture, skeletonTexture, drawingTexture;
        let videoPlane, skeletonPlane, drawingPlane;

        let hands;
        let currentMode = 'none'; // 'none', 'draw', 'erase'
        let lastIndexTipPos = null; // For continuous drawing {x, y}

        const ERASER_RADIUS = 25; // Pixels on the drawingLayerCanvas
        const DRAW_LINE_WIDTH = 5;
        const DRAW_LINE_COLOR = 'cyan';
        const PALM_DOT_RADIUS = 8;
        const PALM_DOT_COLOR = 'lime';

        // --- Helper Functions ---
        function calculatePalmCenter(landmarks) {
            // Use average of wrist (0) and MCPs of index, middle, ring, pinky (5, 9, 13, 17)
            const palmCenterX = (landmarks[0].x + landmarks[5].x + landmarks[9].x + landmarks[13].x + landmarks[17].x) / 5;
            const palmCenterY = (landmarks[0].y + landmarks[5].y + landmarks[9].y + landmarks[13].y + landmarks[17].y) / 5;
            return { x: palmCenterX, y: palmCenterY };
        }

        // --- Initialization Functions ---

        // 1. CAMERA SETUP
        async function setupCamera() {
            console.log("Setting up camera...");
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'user', width: { ideal: 1280 }, height: { ideal: 720 } }
                });
                videoElement.srcObject = stream;
                return new Promise((resolve) => {
                    videoElement.onloadedmetadata = () => {
                        console.log("Camera feed loaded. Video dimensions:", videoElement.videoWidth, "x", videoElement.videoHeight);
                        resolve();
                    };
                });
            } catch (err) {
                console.error("Error accessing webcam:", err);
                alert("Error accessing webcam: " + err.message + "\nPlease ensure you have a webcam connected and have granted permission.");
                throw err; // Propagate error to stop further execution
            }
        }

        // 2. MEDIAPIPE HANDS SETUP
        function setupMediaPipe() {
            console.log("Initializing MediaPipe Hands...");
            hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({
                maxNumHands: 1,
                modelComplexity: 1,
                minDetectionConfidence: 0.6, // Increased for better stability
                minTrackingConfidence: 0.6
            });
            hands.onResults(onResults);
            console.log("MediaPipe Hands initialized.");
        }
        
        // 3. THREE.JS SETUP
        function setupThreeJS() {
            console.log("Setting up Three.js scene...");
            const videoWidth = videoElement.videoWidth;
            const videoHeight = videoElement.videoHeight;

            // Set helper canvas dimensions
            skeletonCanvas.width = videoWidth;
            skeletonCanvas.height = videoHeight;
            drawingLayerCanvas.width = videoWidth;
            drawingLayerCanvas.height = videoHeight;

            // Configure drawing context for user drawings
            drawingCtx.lineWidth = DRAW_LINE_WIDTH;
            drawingCtx.strokeStyle = DRAW_LINE_COLOR;
            drawingCtx.lineCap = 'round';
            drawingCtx.lineJoin = 'round';

            // Renderer
            renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
            renderer.setSize(videoWidth, videoHeight);
            // CSS will scale the canvas to fit viewport via #threeCanvas style
            
            // Scene
            scene = new THREE.Scene();

            // Camera (Orthographic)
            // This makes 1 unit in Three.js space correspond to 1 pixel on the source video/canvases
            camera = new THREE.OrthographicCamera(videoWidth / -2, videoWidth / 2, videoHeight / 2, videoHeight / -2, 1, 1000);
            camera.position.z = 100; // Position camera to see the planes

            // Video Plane (Background)
            videoTexture = new THREE.VideoTexture(videoElement);
            const videoMaterial = new THREE.MeshBasicMaterial({ map: videoTexture });
            videoPlane = new THREE.Mesh(new THREE.PlaneGeometry(videoWidth, videoHeight), videoMaterial);
            videoPlane.position.z = 0; // Furthest back
            videoPlane.scale.x = -1; // Mirror the video feed
            scene.add(videoPlane);

            // Skeleton Plane
            skeletonTexture = new THREE.CanvasTexture(skeletonCanvas);
            const skeletonMaterial = new THREE.MeshBasicMaterial({ map: skeletonTexture, transparent: true });
            skeletonPlane = new THREE.Mesh(new THREE.PlaneGeometry(videoWidth, videoHeight), skeletonMaterial);
            skeletonPlane.position.z = 1; // In front of video
            scene.add(skeletonPlane);

            // Drawing Layer Plane
            drawingTexture = new THREE.CanvasTexture(drawingLayerCanvas);
            const drawingMaterial = new THREE.MeshBasicMaterial({ map: drawingTexture, transparent: true });
            drawingPlane = new THREE.Mesh(new THREE.PlaneGeometry(videoWidth, videoHeight), drawingMaterial);
            drawingPlane.position.z = 2; // In front of skeleton
            scene.add(drawingPlane);
            
            console.log("Three.js scene configured.");
        }

        // --- MEDIAPIPE RESULTS CALLBACK & DRAWING/ERASING LOGIC ---
        function onResults(results) {
            const videoWidth = videoElement.videoWidth;
            const videoHeight = videoElement.videoHeight;

            // Clear skeleton canvas
            skeletonCtx.clearRect(0, 0, videoWidth, videoHeight);
            // Note: drawingLayerCtx is persistent unless explicitly cleared or erased.

            let handDetected = false;

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                handDetected = true;
                const landmarks = results.multiHandLandmarks[0]; // Assuming maxNumHands = 1

                // --- Coordinate Transformation for Mirrored View ---
                // MediaPipe landmarks are for the raw video. Since videoPlane is mirrored,
                // all drawings on overlay canvases must use mirrored X coordinates.
                const mirroredLandmarks = landmarks.map(lm => ({
                    ...lm, // spread operator to copy visibility etc.
                    x: 1.0 - lm.x // Mirror X
                }));

                // --- Draw Skeleton and Palm Dot on skeletonCanvas ---
                // (Using drawingUtils for skeleton)
                if (window.drawConnectors && window.drawLandmarks) {
                    drawConnectors(skeletonCtx, mirroredLandmarks, HAND_CONNECTIONS, { color: '#FFFFFF', lineWidth: 2 });
                    drawLandmarks(skeletonCtx, mirroredLandmarks, { color: '#FF0000', lineWidth: 1, radius: 3 });
                }

                // Calculate and draw palm center dot
                const palmCenterNorm = calculatePalmCenter(mirroredLandmarks); // Already mirrored
                const palmCenterX_canvas = palmCenterNorm.x * videoWidth;
                const palmCenterY_canvas = palmCenterNorm.y * videoHeight;

                skeletonCtx.beginPath();
                skeletonCtx.arc(palmCenterX_canvas, palmCenterY_canvas, PALM_DOT_RADIUS, 0, 2 * Math.PI);
                skeletonCtx.fillStyle = PALM_DOT_COLOR;
                skeletonCtx.fill();


                // --- Gesture Detection & Mode Setting ---
                // Landmarks: TIPs (4, 8, 12, 16, 20), PIPs (2, 6, 10, 14, 18 for fingers, 2 for thumb IP)
                // Y coordinates: smaller is higher on screen (MediaPipe norm: 0=top, 1=bottom)
                
                // Index finger extended: Tip (8) significantly above PIP (6)
                const indexTipY = landmarks[8].y; // Use original landmarks for gesture logic
                const indexPipY = landmarks[6].y;
                const isIndexExtended = indexTipY < indexPipY - 0.04; // Threshold for "significantly"

                // Other fingers (Middle, Ring, Pinky, Thumb) curled: Tip below or near PIP/IP
                const isMiddleCurled = landmarks[12].y > landmarks[10].y - 0.03;
                const isRingCurled = landmarks[16].y > landmarks[14].y - 0.03;
                const isPinkyCurled = landmarks[20].y > landmarks[18].y - 0.03;
                const isThumbCurled = landmarks[4].y > landmarks[2].y - 0.03; // Thumb tip vs MCP/CMC (landmark 2 is Thumb MCP)

                // Open Palm: All fingertips extended (above their PIP/IP joints)
                const isOpenPalm = (landmarks[4].y < landmarks[2].y - 0.02) && // Thumb
                                   (landmarks[8].y < landmarks[6].y - 0.02) && // Index
                                   (landmarks[12].y < landmarks[10].y - 0.02) && // Middle
                                   (landmarks[16].y < landmarks[14].y - 0.02) && // Ring
                                   (landmarks[20].y < landmarks[18].y - 0.02);  // Pinky

                let newMode = 'none';
                if (isOpenPalm) {
                    newMode = 'erase';
                } else if (isIndexExtended && isMiddleCurled && isRingCurled && isPinkyCurled && isThumbCurled) {
                    newMode = 'draw';
                }
                
                if (currentMode !== newMode) {
                    currentMode = newMode;
                    // console.log("Mode changed to:", currentMode);
                    if (currentMode !== 'draw') {
                        lastIndexTipPos = null; // Reset last position if not drawing
                        drawingCtx.beginPath(); // Start a new path for next drawing session
                    }
                }

                // --- Drawing/Erasing Logic on drawingLayerCanvas ---
                if (currentMode === 'draw') {
                    const indexTipMirrored = mirroredLandmarks[8]; // Use mirrored for drawing
                    const currentX = indexTipMirrored.x * videoWidth;
                    const currentY = indexTipMirrored.y * videoHeight;

                    drawingCtx.strokeStyle = DRAW_LINE_COLOR; // Ensure color is set
                    drawingCtx.lineWidth = DRAW_LINE_WIDTH;   // Ensure width is set
                    drawingCtx.globalCompositeOperation = 'source-over';


                    if (lastIndexTipPos) {
                        drawingCtx.moveTo(lastIndexTipPos.x, lastIndexTipPos.y);
                        drawingCtx.lineTo(currentX, currentY);
                        drawingCtx.stroke();
                    } else {
                        // Start of a new line segment, move to current point and draw a small dot
                        drawingCtx.beginPath();
                        drawingCtx.moveTo(currentX, currentY);
                        // Optionally draw a small circle for the first point if lineTo isn't immediately called
                        // drawingCtx.arc(currentX, currentY, DRAW_LINE_WIDTH / 2, 0, 2 * Math.PI);
                        // drawingCtx.fill();
                    }
                    lastIndexTipPos = { x: currentX, y: currentY };
                } else if (currentMode === 'erase') {
                    // Use the palm center calculated earlier (already in mirrored canvas coords)
                    drawingCtx.globalCompositeOperation = 'destination-out'; // Erase mode
                    drawingCtx.beginPath();
                    drawingCtx.arc(palmCenterX_canvas, palmCenterY_canvas, ERASER_RADIUS, 0, 2 * Math.PI);
                    drawingCtx.fill();
                    drawingCtx.globalCompositeOperation = 'source-over'; // Reset composite mode
                    lastIndexTipPos = null; // Ensure drawing doesn't continue from old pos
                }

            } else { // No hand detected
                if (currentMode !== 'none') {
                    // console.log("No hand detected, mode set to 'none'");
                    currentMode = 'none';
                    lastIndexTipPos = null;
                    drawingCtx.beginPath(); // Reset path if hand is lost
                }
            }

            // Mark textures for update in Three.js
            skeletonTexture.needsUpdate = true;
            drawingTexture.needsUpdate = true;
        }

        // --- MAIN ANIMATION LOOP ---
        async function animationLoop() {
            if (videoElement. Halted || videoElement.paused || videoElement.ended || videoElement.readyState < HTMLMediaElement.HAVE_ENOUGH_DATA) {
                requestAnimationFrame(animationLoop);
                return;
            }

            // Send video frame to MediaPipe for processing.
            // `hands.send` returns a Promise that resolves after `onResults` is called.
            try {
                await hands.send({ image: videoElement });
            } catch (e) {
                console.error("Error sending frame to MediaPipe:", e);
            }
            
            // Render Three.js scene
            renderer.render(scene, camera);

            requestAnimationFrame(animationLoop);
        }
        
        // --- STARTUP SEQUENCE ---
        async function main() {
            try {
                await setupCamera();
                videoElement.play(); // Start playing the video to get frames
                setupMediaPipe();
                setupThreeJS(); // Depends on video dimensions, so after camera setup and play
                
                console.log("All systems go. Starting animation loop.");
                animationLoop(); // Start the main processing and rendering loop
            } catch (error) {
                console.error("Initialization failed:", error);
                // Error already alerted in setupCamera or could be handled here
            }
        }

        main();

        // Handle window resize (optional, but good practice)
        window.addEventListener('resize', () => {
            if (renderer && camera && videoElement.videoWidth > 0) {
                const videoWidth = videoElement.videoWidth;
                const videoHeight = videoElement.videoHeight;

                // Update renderer and camera to maintain aspect ratio if canvas is styled with object-fit
                // Or, if you want to fill the new window size and adjust camera:
                // renderer.setSize(window.innerWidth, window.innerHeight);
                // camera.left = window.innerWidth / -2;
                // camera.right = window.innerWidth / 2;
                // camera.top = window.innerHeight / 2;
                // camera.bottom = window.innerHeight / -2;
                // camera.updateProjectionMatrix();
                // The current setup with threeCanvas CSS handling the scaling is simpler.
            }
        });

    </script>
</body>
</html>