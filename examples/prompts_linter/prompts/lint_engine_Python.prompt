The `lint_engine` module is the central orchestrator of the PDD Prompt Linter backend. Its primary responsibility is to coordinate the entire linting workflow: accepting raw prompt text (and optional configuration), invoking the `Parser` to structure the content, resolving includes via the `IncludeResolver` (if enabled), iterating through registered rules in the `Registry`, and aggregating all findings into a standardized `LintReport`. This module acts as the glue between the raw input and the structured output, ensuring that the linting process is deterministic, stateless, and robust against malformed inputs.

Requirements
1.  **Orchestration:** The engine must implement a main entry point (e.g., `lint_prompt`) that accepts raw text, a file path (optional, for reporting), and a configuration object (options).
2.  **Parsing Integration:** It must instantiate or call the `Parser` to convert raw text into a structured object containing sections, tags, and a line map.
3.  **Include Resolution:** If the `resolve_includes` option is true, it must use the `IncludeResolver` to process `<include>` tags, calculate resolved token counts, and detect potential context dumps. If false, it should skip file I/O but still parse the tags.
4.  **Rule Execution:** It must retrieve all active rules from the `Registry` (or a specific subset if configured) and execute them against the parsed structure.
5.  **Aggregation:** It must collect `Finding` objects from all rules and the parser (if parsing errors occur) and compile them into a `LintReport`.
6.  **Scoring:** It must calculate a heuristic score based on the severity and count of findings (starting at 100 and deducting points for errors, warnings, and info).
7.  **Error Handling:** The engine must gracefully handle parsing failures (returning a report with a fatal error finding) and individual rule failures (logging the error but not crashing the entire lint process).
8.  **Statelessness:** The engine must not retain state between lint calls; each invocation is independent.

Dependencies
<models_findings>
  <include>context/models_findings_example.py</include>
</models_findings>
<rules_registry>
  <include>context/rules_registry_example.py</include>
</rules_registry>
<parser>
  <include>context/parser_example.py</include>
</parser>
<include_resolver>
  <include>context/include_resolver_example.py</include>
</include_resolver>

Prompt Dependencies:
- models_findings_Python.prompt
- rules_registry_Python.prompt
- parser_Python.prompt
- include_resolver_Python.prompt

Instructions
-   Define a `LintEngine` class or a functional equivalent that encapsulates the linting logic.
-   Implement a method `lint(content: str, file_path: str = "stdin", options: dict = None) -> LintReport`.
-   **Step 1: Parse.** Call the parser. If the parser raises a critical exception, catch it and return a `LintReport` with a single "Critical" severity finding explaining the parse failure.
-   **Step 2: Resolve Includes.** If `options.resolve_includes` is True, invoke the `IncludeResolver`. Update the report's `resolved_tokens` and `estimated_tokens` fields based on the result.
-   **Step 3: Load Rules.** Fetch rules from the `Registry`. If a configuration is provided (e.g., enabled/disabled rules), filter the list accordingly.
-   **Step 4: Execute Rules.** Loop through the rules. Pass the parsed structure (and resolved context if available) to each rule. Collect the returned `Finding` objects.
    -   Wrap rule execution in a try/except block to prevent a buggy rule from crashing the engine. If a rule fails, add a "Warning" finding indicating an internal linter error for that specific rule.
-   **Step 5: Score & Summarize.** Calculate the final score:
    -   Start: 100
    -   Error: -15 (cap -45)
    -   Warn: -7 (cap -35)
    -   Info: -2 (cap -20)
    -   Min Score: 0
-   Construct and return the final `LintReport` object using the Pydantic models defined in `models_findings`.

Deliverable
-   `src/backend/core/lint_engine.py`: The implementation file containing the `LintEngine` class and helper logic.

Implementation assumptions (explicit)
-   The `Parser` returns a structure that rules can easily traverse (e.g., a dictionary of sections or a custom object).
-   Rules follow a standard interface (e.g., `check(parsed_prompt) -> List[Finding]`).
-   The `Registry` is already populated or has a discovery mechanism; the engine just queries it.
-   Token estimation is a simple heuristic (chars / 4) provided by the `IncludeResolver` or a utility, not a full tokenizer.